{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaecf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ee412",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives_folder = \"/media/jaume/DATA/Data/Urblauna_SFTP/UKB_Cardiac_BIDS/derivatives\"\n",
    "data_path = os.path.join(derivatives_folder, 'GraphClassification')\n",
    "nodes_filename = os.path.join(derivatives_folder, \"nodes_data.parquet\")\n",
    "global_filename = os.path.join(derivatives_folder, \"global_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d12367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the nodes data\n",
    "nodes_data = pd.read_parquet(nodes_filename)\n",
    "\n",
    "# Load the global data\n",
    "global_data = pd.read_parquet(global_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_biomarkers(node_info, region, subject='test'):\n",
    "    node_info['Strain_Radial'] = node_info['Strain_Radial'].astype(float)\n",
    "    node_info['Strain_Circum'] = node_info['Strain_Circum'].astype(float)\n",
    "    node_info['Thickness_Mean'] = node_info['Thickness_Mean'].astype(float)\n",
    "\n",
    "    max_thick = node_info.query(f\"Region=='{region}'\")['Thickness_Mean'].max()\n",
    "    min_thick = node_info.query(f\"Region=='{region}'\")['Thickness_Mean'].min()\n",
    "    std_thick = node_info.query(f\"Region=='{region}'\")['Thickness_Mean'].std()\n",
    "    mean_thick = node_info.query(f\"Region=='{region}'\")['Thickness_Mean'].mean()\n",
    "    max_radial_strain = node_info.query(f\"Region=='{region}'\")['Strain_Radial'].max()\n",
    "    max_circum_strain = node_info.query(f\"Region=='{region}'\")['Strain_Circum'].max()\n",
    "    array_data = np.array([max_thick, min_thick, std_thick, mean_thick, max_radial_strain, max_circum_strain])[:, np.newaxis]\n",
    "    col_names = ['Max Thickness', 'Min Thickness', 'Std Thickness', 'Mean Thickness', 'Max Radial Strain', 'Max Circum Strain']\n",
    "    col_names = [f'{region}_{x}' for x in col_names]\n",
    "    df_node_data = pd.DataFrame(array_data.T, columns=col_names, index=[subject])\n",
    "    df_node_data.index.name = 'Subject'\n",
    "\n",
    "    return df_node_data\n",
    "\n",
    "\n",
    "def identify_early_relaxation(node_info, global_info):\n",
    "    node_info['Volume_Index'] = node_info['Volume_Index'].astype(float)\n",
    "    node_info['Thickness_Mean'] = node_info['Thickness_Mean'].astype(float)\n",
    "    node_info['Cycle'] = node_info['Cycle'].astype(float)\n",
    "    es_time = global_info['es_cycle_time'].astype(float).values[0]\n",
    "\n",
    "    # Compute the derivative of the thickness\n",
    "    volume_derivative_lv = node_info.query(\"Region=='LV'\").set_index(\"Cycle\").sort_index()[['Volume_Index']].diff().rolling(3).sum()\n",
    "    thickness_derivative_lv = node_info.query(\"Region=='LV_Myo'\").set_index(\"Cycle\").sort_index()[['Thickness_Mean']].diff().rolling(3).sum()\n",
    "\n",
    "    volume_derivative_rv = node_info.query(\"Region=='RV'\").set_index(\"Cycle\").sort_index()[['Volume_Index']].diff().rolling(3).sum()\n",
    "    thickness_derivative_rv = node_info.query(\"Region=='RV_Myo'\").set_index(\"Cycle\").sort_index()[['Thickness_Mean']].diff().rolling(3).sum()\n",
    "\n",
    "    # Identify 0s after ES time\n",
    "    thickness_derivative_lv = thickness_derivative_lv[thickness_derivative_lv.index > es_time]\n",
    "    volume_derivative_lv = volume_derivative_lv[volume_derivative_lv.index > es_time]\n",
    "\n",
    "    thickness_derivative_rv = thickness_derivative_rv[thickness_derivative_rv.index > es_time]\n",
    "    volume_derivative_rv = volume_derivative_rv[volume_derivative_rv.index > es_time]\n",
    "\n",
    "    # For security discard first 3 time-pints and last 3 time-points\n",
    "    if len(thickness_derivative_lv) < 5:\n",
    "        early_relax_time_lv = thickness_derivative_lv.iloc[np.argmax(thickness_derivative_lv)].name\n",
    "        early_relax_time_rv = thickness_derivative_rv.iloc[np.argmax(thickness_derivative_rv)].name\n",
    "    else:\n",
    "        early_relax_time_lv = thickness_derivative_lv.iloc[2:-2].iloc[np.argmax(thickness_derivative_lv.iloc[2:-2])].name\n",
    "        early_relax_time_rv = thickness_derivative_rv.iloc[2:-2].iloc[np.argmax(thickness_derivative_rv.iloc[2:-2])].name\n",
    "    early_relax_time = np.mean([early_relax_time_lv, early_relax_time_rv])\n",
    "\n",
    "    return early_relax_time\n",
    "\n",
    "\n",
    "def get_relaxation_strain_and_ratios(node_info, global_info, early_relax_time, region):\n",
    "    # Get contraction and relaxation times\n",
    "    node_info['Cycle'] = node_info['Cycle'].astype(float)\n",
    "    ed_time = global_info['ed_cycle_time'].astype(float).values[0]\n",
    "    es_time = global_info['es_cycle_time'].astype(float).values[0]\n",
    "    es_data = node_info.query(f\"Cycle=={es_time}\").reset_index(drop=True).set_index('Region')\n",
    "    ed_data = node_info.query(f\"Cycle=={ed_time}\").reset_index(drop=True).set_index('Region')\n",
    "    end_data = node_info.query(\"Cycle==1\").reset_index(drop=True).set_index('Region')\n",
    "\n",
    "    # Find closest Cycle to early relaxation time\n",
    "    cycle_times = node_info['Cycle'].astype(float).unique()\n",
    "    distance = np.abs(cycle_times - early_relax_time)\n",
    "    distance_idx = np.argmin(distance)\n",
    "    early_relax_time_cycle = cycle_times[distance_idx]\n",
    "    early_data = node_info.query(f\"Cycle=={early_relax_time_cycle}\").reset_index(drop=True).set_index('Region')\n",
    "\n",
    "    # print(f\"ED time: {ed_time}, ES time: {es_time}, Early Relaxation time: {early_relax_time}\")\n",
    "    ed_data = ed_data.astype(float)\n",
    "    es_data = es_data.astype(float)    \n",
    "    contraction_data = (ed_data - es_data)  # ED -> ES\n",
    "    relaxation_data = (end_data - es_data)  # End of cycle -> ES\n",
    "    early_relax_data = (early_data - es_data) # Early relaxation -> ES\n",
    "\n",
    "    ratio_data = relaxation_data / contraction_data\n",
    "    ratio_early = early_relax_data / contraction_data\n",
    "    \n",
    "    contraction_data = contraction_data.loc[[region]].astype(float)\n",
    "    contraction_data = contraction_data[['Strain_Radial', 'Strain_Circum']].rename(columns={'Strain_Radial': f'{region}_Strain_Radial_Contraction',\n",
    "                                                                                            'Strain_Circum': f'{region}_Strain_Circum_Contraction'})\n",
    "    \n",
    "    relaxation_data = relaxation_data.loc[[region]].astype(float)\n",
    "    relaxation_data = relaxation_data[['Strain_Radial', 'Strain_Circum']].rename(columns={'Strain_Radial': f'{region}_Strain_Radial_Relaxation',\n",
    "                                                                                          'Strain_Circum': f'{region}_Strain_Circum_Relaxation'})\n",
    "    \n",
    "    early_relax_data = early_relax_data.loc[[region]].astype(float)\n",
    "    early_relax_data = early_relax_data[['Strain_Radial', 'Strain_Circum']].rename(columns={'Strain_Radial': f'{region}_Strain_Radial_Early_Relaxation',\n",
    "                                                                                            'Strain_Circum': f'{region}_Strain_Circum_Early_Relaxation'})\n",
    "    \n",
    "    ratio_data = ratio_data.loc[[region]].astype(float)\n",
    "    ratio_data = ratio_data[['Strain_Radial', 'Strain_Circum']].rename(columns={'Strain_Radial': f'{region}_Strain_Radial_Ratio',\n",
    "                                                                                'Strain_Circum': f'{region}_Strain_Circum_Ratio'})\n",
    "    \n",
    "    ratio_early = ratio_early.loc[[region]].astype(float)\n",
    "    ratio_early = ratio_early[['Strain_Radial', 'Strain_Circum']].rename(columns={'Strain_Radial': f'{region}_Strain_Radial_Ratio_Early',\n",
    "                                                                                  'Strain_Circum': f'{region}_Strain_Circum_Ratio_Early'})\n",
    "    \n",
    "    contraction_data = contraction_data.astype(float)\n",
    "    relaxation_data = relaxation_data.astype(float)\n",
    "    early_relax_data = early_relax_data.astype(float)\n",
    "    ratio_data = ratio_data.astype(float)\n",
    "    ratio_early = ratio_early.astype(float)\n",
    "\n",
    "    summary_strain = pd.concat([contraction_data, relaxation_data, early_relax_data, ratio_data, ratio_early], axis=1)\n",
    "\n",
    "    return summary_strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac493f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the nodes data\n",
    "# ==========================\n",
    "# Get the LV and RV biomarkers\n",
    "# ==========================\n",
    "biomarkers_filename = os.path.join(derivatives_folder, \"biomarkers.csv\")\n",
    "redo = True\n",
    "if not os.path.isfile(biomarkers_filename) or redo:\n",
    "    df_data = pd.DataFrame(data=[])\n",
    "    subjects = list(nodes_data['Subject'].unique())\n",
    "    for subject in subjects:        \n",
    "        nodes_file = nodes_data.query(f\"Subject=='{subject}'\").copy()\n",
    "        nodes_file.set_index('Subject', inplace=True)\n",
    "        nodes_file.drop(columns=['Label'], inplace=True)\n",
    "\n",
    "        global_file = global_data.query(f\"Subject=='{subject}'\").copy()\n",
    "        global_file.set_index('Subject', inplace=True)\n",
    "\n",
    "        df_node_data_lv = get_basic_biomarkers(nodes_file, 'LV_Myo', subject=subject)\n",
    "        df_node_data_rv = get_basic_biomarkers(nodes_file, 'RV_Myo', subject=subject)\n",
    "        early_relax_time = identify_early_relaxation(nodes_file, global_file)\n",
    "        summary_lv = get_relaxation_strain_and_ratios(nodes_file, global_file, early_relax_time, 'LV_Myo')\n",
    "        summary_rv = get_relaxation_strain_and_ratios(nodes_file, global_file, early_relax_time, 'RV_Myo')\n",
    "\n",
    "        summary_lv.index = [subject]\n",
    "        summary_lv.index.name = 'Subject'\n",
    "\n",
    "        summary_rv.index = [subject]\n",
    "        summary_rv.index.name = 'Subject'\n",
    "\n",
    "        df_node_data = pd.concat([summary_lv, summary_rv, df_node_data_lv, df_node_data_rv, global_file], axis=1)\n",
    "        df_data = pd.concat([df_data, df_node_data])\n",
    "    \n",
    "    df_data.index.name = 'Subject'\n",
    "    df_data.reset_index(inplace=True)\n",
    "    df_data.sort_values('Subject', inplace=True)\n",
    "    df_data.reset_index(drop=True, inplace=True)\n",
    "    df_data.to_csv(biomarkers_filename)\n",
    "else:\n",
    "    df_data = pd.read_csv(biomarkers_filename, index_col=0)\n",
    "\n",
    "df_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyMultiplex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
